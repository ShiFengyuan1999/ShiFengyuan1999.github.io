# üìù Projects

[//]: # (<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Github Project</div><a href="images/Open-MAGVIT2.png"><img src='images/Open-MAGVIT2.png' alt="sym" width="100%"></a></div></div>)

[//]: # (<div class='paper-box-text' markdown="1">)

[//]: # ()
[//]: # (<b>OPEN-MAGVIT2: An Open-source Project Toward Democratizing Auto-Regressive Visual Generation</b><br>)

[//]: # (Zhuoyan Luo*, <b>Fengyuan Shi*</b>, Yixiao Ge, Yujiu Yang, Limin Wang, Ying Shan<br>)

[//]: # ([<a href="https://arxiv.org/abs/2409.04410">ArXiv</a>][<a href="https://github.com/TencentARC/Open-MAGVIT2">Code</a>])

[//]: # (<div style="text-align: justify">)

[//]: # (<ul>)

[//]: # (      <li>An open-source replication of Google‚Äôs MAGVIT-v2 tokenizer with a super-large codebook &#40;i.e., 2^18 codes&#41;, and it achieves the state-of-the-art reconstruction performance &#40;1.17 rFID&#41; on ImageNet 256 x 256.</li>)

[//]: # (      <li>A family of auto-regressive image generation models ranging from 300M to 1.5B, which adapts super-large codebook into vanilla auto-regressive generation.</li>)

[//]: # (</ul>)

[//]: # (</div>)

[//]: # (</div>)

[//]: # (</div>)


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Github Project</div><a href="images/seed-voken.png"><img src='images/seed-voken.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>SEED-Voken: A Series of Powerful Visual Tokenizers</b><br>
The project aims to provide advanced visual tokenizers for autoregressive visual generation and currently supports the following methods:
<div style="text-align: justify">
<ul>
<li><a href="https://arxiv.org/abs/2409.04410">Open-MAGVIT2: An Open-source Project Toward Democratizing Auto-Regressive Visual Generation</a><br>
Zhuoyan Luo*, <b>Fengyuan Shi*</b>, Yixiao Ge, Yujiu Yang, Limin Wang, Ying Shan<br></li>
<li><a href="https://arxiv.org/abs/2412.02692">IBQ: Taming Scalable Visual Tokenizer for Autoregressive Image Generation</a><br>
<b>Fengyuan Shi*</b>, Zhuoyan Luo*, Yixiao Ge, Yujiu Yang, Limin Wang, Ying Shan<br></li>
</ul>
</div>

</div>
</div>



